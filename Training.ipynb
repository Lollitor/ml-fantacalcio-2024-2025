{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a35abcb-3ab3-4a54-9103-7bfc002f154e",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation for Goals Prediction\n",
    "\n",
    "This code trains several machine learning models to predict player goals based on historical data, and selects the best model based on Mean Squared Error (MSE).\n",
    "\n",
    "### Key Steps:\n",
    "1. **Data Loading and Preprocessing**: \n",
    "   - The dataset is loaded, and the 'Age' column is dropped. Features (`X`) include player stats, while the target (`y`) is goals.\n",
    "   - Categorical columns ('Player', 'Squad', 'Comp') are processed using **OneHotEncoder** for linear models and **LabelEncoder** for tree-based models and SVR.\n",
    "\n",
    "2. **Model Training**: \n",
    "   - The dataset is split into training and test sets.\n",
    "   - Various models, including Linear Regression, Ridge, Random Forest, and XGBoost, are trained and evaluated using MSE.\n",
    "\n",
    "3. **Model Selection and Saving**: \n",
    "   - The model with the lowest MSE is selected and retrained on the entire dataset.\n",
    "   - The best model is saved to a file (`best_model.pkl`) for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49019508-0a61-4fd1-89f2-034e5fdb97d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Mean Squared Error: 11.924909219150187\n",
      "Ridge Regression - Mean Squared Error: 9.863551486834377\n",
      "Lasso Regression - Mean Squared Error: 11.051687344007483\n",
      "Decision Tree - Mean Squared Error: 15.979288770142437\n",
      "Random Forest - Mean Squared Error: 10.285688657029041\n",
      "Gradient Boosting - Mean Squared Error: 10.275249778360113\n",
      "XGBoost - Mean Squared Error: 10.740106213522557\n",
      "SVR - Mean Squared Error: 11.82464685472684\n",
      "\n",
      "Best Model: Ridge Regression with Mean Squared Error: 9.863551486834377\n",
      "\n",
      "The best model 'Ridge Regression' has been saved to 'best_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'training_data_with_goals_target.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the \"Age\" column\n",
    "df = df.drop(columns=[\"Age\"])\n",
    "\n",
    "# Define the features and target\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Define which columns are categorical\n",
    "categorical_columns = [\"Player\", \"Squad\", \"Comp\"]\n",
    "\n",
    "# OneHotEncoder for linear models\n",
    "onehot_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the other numeric columns as they are\n",
    ")\n",
    "\n",
    "# LabelEncoder for tree-based models\n",
    "# Apply LabelEncoder for categorical columns\n",
    "label_encoded_X = X.copy()\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    label_encoded_X[col] = le.fit_transform(label_encoded_X[col])\n",
    "    label_encoders[col] = le  # Save the encoder for potential future use\n",
    "\n",
    "# Split the data into train and test sets for both one-hot and label encoded data\n",
    "X_train_onehot, X_test_onehot, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_label, X_test_label, _, _ = train_test_split(label_encoded_X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# StandardScaler for models that require scaling (e.g., SVR)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': Pipeline(steps=[('preprocessor', onehot_preprocessor), ('regressor', LinearRegression())]),\n",
    "    'Ridge Regression': Pipeline(steps=[('preprocessor', onehot_preprocessor), ('regressor', Ridge())]),\n",
    "    'Lasso Regression': Pipeline(steps=[('preprocessor', onehot_preprocessor), ('regressor', Lasso())]),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42),\n",
    "    'SVR': Pipeline(steps=[('scaler', scaler), ('regressor', SVR())])  # SVR with scaling\n",
    "}\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate the models\n",
    "for model_name, model in models.items():\n",
    "    if model_name in ['Linear Regression', 'Ridge Regression', 'Lasso Regression']:  # Linear models need OneHotEncoded data\n",
    "        model.fit(X_train_onehot, y_train)\n",
    "        y_pred = model.predict(X_test_onehot)\n",
    "    elif model_name == 'SVR':  # SVR needs scaled numerical data\n",
    "        model.fit(X_train_label, y_train)  # SVR works with label encoded data and scaling\n",
    "        y_pred = model.predict(X_test_label)\n",
    "    else:  # Tree-based models and XGBoost work with label encoded data\n",
    "        model.fit(X_train_label, y_train)\n",
    "        y_pred = model.predict(X_test_label)\n",
    "    \n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    results[model_name] = mse\n",
    "    print(f\"{model_name} - Mean Squared Error: {mse}\")\n",
    "\n",
    "# Identify the best model based on lowest MSE\n",
    "best_model_name = min(results, key=results.get)\n",
    "print(f\"\\nBest Model: {best_model_name} with Mean Squared Error: {results[best_model_name]}\")\n",
    "\n",
    "# Save the best model (retrain on the full dataset for final use)\n",
    "if best_model_name in ['Linear Regression', 'Ridge Regression', 'Lasso Regression']:\n",
    "    best_model = clone(models[best_model_name])\n",
    "    best_model.fit(X, y)  # Fit on the entire dataset with OneHotEncoding\n",
    "elif best_model_name == 'SVR':\n",
    "    best_model = clone(models[best_model_name])\n",
    "    best_model.fit(label_encoded_X, y)  # Fit on the entire dataset with LabelEncoding and scaling\n",
    "else:\n",
    "    best_model = clone(models[best_model_name])\n",
    "    best_model.fit(label_encoded_X, y)  # Fit on the entire dataset with LabelEncoding\n",
    "\n",
    "# Save the best model to a file\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"\\nThe best model '{best_model_name}' has been saved to 'best_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1400d53-575e-4064-8c97-d71de292aec7",
   "metadata": {},
   "source": [
    "# Prediction for the Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "678fb760-217d-4fc6-8057-61be939d6013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved Ridge regression model\n",
    "with open('best_model.pkl', 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "# Load the new dataset\n",
    "new_data_path = 'prediction_data_2024_2025.csv'\n",
    "new_df = pd.read_csv(new_data_path)\n",
    "\n",
    "# Drop the \"Age\" column and rows with NaN values\n",
    "new_df = new_df.drop(columns=[\"Age\"]).dropna()\n",
    "\n",
    "# Extract the necessary columns for processing and prediction\n",
    "categorical_columns = [\"Player\", \"Squad\", \"Comp\"]\n",
    "\n",
    "# Prepare the feature set for prediction by dropping the target column (if present) and keeping relevant features\n",
    "X_new = new_df.drop(columns=['target'], errors='ignore')\n",
    "\n",
    "# Ensure the categorical columns are treated the same way as in training\n",
    "# Apply the saved OneHotEncoder for linear models (Ridge regression)\n",
    "X_new_processed = best_model.named_steps['preprocessor'].transform(X_new)\n",
    "\n",
    "# Make predictions using the best model\n",
    "predictions = best_model.named_steps['regressor'].predict(X_new_processed)\n",
    "\n",
    "# Round the predicted goals to the nearest integer\n",
    "rounded_predictions = np.round(predictions)\n",
    "\n",
    "# Add the rounded predicted goals to the original dataset\n",
    "new_df['predicted Goals'] = rounded_predictions\n",
    "\n",
    "# Keep only the necessary columns: \"Player\", \"Squad\", \"Comp\", and \"predicted Goals\"\n",
    "final_df = new_df[[\"Player\", \"Squad\", \"Comp\", \"predicted Goals\"]]\n",
    "\n",
    "# Sort the dataframe by predicted goals in descending order\n",
    "final_df = final_df.sort_values(by=\"predicted Goals\", ascending=False)\n",
    "\n",
    "# Save the final dataframe with predictions to a new CSV file\n",
    "output_file_path = 'predictions.csv'  # Update this path as needed\n",
    "final_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b465e655-42cb-4c75-9c11-02f9f3c5f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Mean Squared Error: 3.8236537952642258\n",
      "Ridge Regression - Mean Squared Error: 3.326861999400568\n",
      "Lasso Regression - Mean Squared Error: 2.988557005618711\n",
      "Decision Tree - Mean Squared Error: 4.89390331973031\n",
      "Random Forest - Mean Squared Error: 2.9456485749146\n",
      "Gradient Boosting - Mean Squared Error: 2.884988183228712\n",
      "XGBoost - Mean Squared Error: 3.36557681233255\n",
      "SVR - Mean Squared Error: 2.8715897972669895\n",
      "\n",
      "Best Model: SVR with Mean Squared Error: 2.8715897972669895\n",
      "\n",
      "The best model 'SVR' has been saved to 'best_model_assist.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'training_data_with_assists_target.csv' \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the \"Age\" column\n",
    "df = df.drop(columns=[\"Age\"])\n",
    "\n",
    "# Define the features and target\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Define which columns are categorical\n",
    "categorical_columns = [\"Player\", \"Squad\", \"Comp\"]\n",
    "\n",
    "# OneHotEncoder for linear models\n",
    "onehot_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "# LabelEncoder for tree-based models\n",
    "# Apply LabelEncoder for categorical columns\n",
    "label_encoded_X = X.copy()\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    label_encoded_X[col] = le.fit_transform(label_encoded_X[col])\n",
    "    label_encoders[col] = le  # Save the encoder for potential future use\n",
    "\n",
    "# Split the data into train and test sets for both one-hot and label encoded data\n",
    "X_train_onehot, X_test_onehot, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_label, X_test_label, _, _ = train_test_split(label_encoded_X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# StandardScaler for models that require scaling (e.g., SVR)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': Pipeline(steps=[('preprocessor', onehot_preprocessor), ('regressor', LinearRegression())]),\n",
    "    'Ridge Regression': Pipeline(steps=[('preprocessor', onehot_preprocessor), ('regressor', Ridge())]),\n",
    "    'Lasso Regression': Pipeline(steps=[('preprocessor', onehot_preprocessor), ('regressor', Lasso())]),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42),\n",
    "    'SVR': Pipeline(steps=[('scaler', scaler), ('regressor', SVR())])  # SVR with scaling\n",
    "}\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate the models\n",
    "for model_name, model in models.items():\n",
    "    if model_name in ['Linear Regression', 'Ridge Regression', 'Lasso Regression']:  # Linear models need OneHotEncoded data\n",
    "        model.fit(X_train_onehot, y_train)\n",
    "        y_pred = model.predict(X_test_onehot)\n",
    "    elif model_name == 'SVR':  # SVR needs scaled numerical data\n",
    "        model.fit(X_train_label, y_train)  # SVR works with label encoded data and scaling\n",
    "        y_pred = model.predict(X_test_label)\n",
    "    else:  # Tree-based models and XGBoost work with label encoded data\n",
    "        model.fit(X_train_label, y_train)\n",
    "        y_pred = model.predict(X_test_label)\n",
    "    \n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    results[model_name] = mse\n",
    "    print(f\"{model_name} - Mean Squared Error: {mse}\")\n",
    "\n",
    "# Identify the best model based on lowest MSE\n",
    "best_model_name = min(results, key=results.get)\n",
    "print(f\"\\nBest Model: {best_model_name} with Mean Squared Error: {results[best_model_name]}\")\n",
    "\n",
    "# Save the best model (retrain on the full dataset for final use)\n",
    "if best_model_name in ['Linear Regression', 'Ridge Regression', 'Lasso Regression']:\n",
    "    best_model = clone(models[best_model_name])\n",
    "    best_model.fit(X, y)  # Fit on the entire dataset with OneHotEncoding\n",
    "elif best_model_name == 'SVR':\n",
    "    best_model = clone(models[best_model_name])\n",
    "    best_model.fit(label_encoded_X, y)  # Fit on the entire dataset with LabelEncoding and scaling\n",
    "else:\n",
    "    best_model = clone(models[best_model_name])\n",
    "    best_model.fit(label_encoded_X, y)  # Fit on the entire dataset with LabelEncoding\n",
    "\n",
    "# Save the best model to a file\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"\\nThe best model '{best_model_name}' has been saved to 'best_model_assist.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278eb799-08ba-428d-a48f-09b3456776ea",
   "metadata": {},
   "source": [
    "# Prediction for the Assists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29621b0f-736a-40b0-afe5-51f2a6974186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'predictions_assists.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the saved SVR model\n",
    "with open('best_model.pkl', 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "# Load the new dataset\n",
    "new_data_path = 'prediction_data_2024_2025.csv'\n",
    "new_df = pd.read_csv(new_data_path)\n",
    "\n",
    "# Drop the \"Age\" column and rows with NaN values\n",
    "new_df = new_df.drop(columns=[\"Age\"]).dropna()\n",
    "\n",
    "# Extract the necessary columns for processing and prediction\n",
    "categorical_columns = [\"Player\", \"Squad\", \"Comp\"]\n",
    "\n",
    "# Make a copy of the original categorical columns to preserve original values\n",
    "original_categorical_values = new_df[categorical_columns].copy()\n",
    "\n",
    "# Apply Label Encoding to the categorical columns for the prediction process\n",
    "label_encoded_df = new_df.copy()  # Work with a copy of the dataframe to preserve original values\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    label_encoded_df[col] = le.fit_transform(new_df[col])  # Label encode the data\n",
    "    label_encoders[col] = le  # Save the encoders if needed for future use\n",
    "\n",
    "# Prepare the feature set for prediction by dropping the target column (if present) and keeping relevant features\n",
    "X_new = label_encoded_df.drop(columns=['target'], errors='ignore')\n",
    "\n",
    "# Apply scaling as SVR requires scaled data\n",
    "scaler = best_model.named_steps['scaler']\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "# Make predictions using the best model\n",
    "predictions = best_model.named_steps['regressor'].predict(X_new_scaled)\n",
    "\n",
    "# Round the predicted assists to the nearest integer\n",
    "rounded_predictions = np.round(predictions)\n",
    "\n",
    "# Add the rounded predicted assists to the original dataset\n",
    "new_df['predicted Assists'] = rounded_predictions\n",
    "\n",
    "# Replace the label encoded categorical columns with the original values\n",
    "new_df[categorical_columns] = original_categorical_values\n",
    "\n",
    "# Keep only the necessary columns: \"Player\", \"Squad\", \"Comp\", and \"predicted Assists\"\n",
    "final_df = new_df[[\"Player\", \"Squad\", \"Comp\", \"predicted Assists\"]]\n",
    "\n",
    "# Sort the dataframe by predicted assists in descending order\n",
    "final_df = final_df.sort_values(by=\"predicted Assists\", ascending=False)\n",
    "\n",
    "# Save the final dataframe with predictions to a new CSV file\n",
    "output_file_path = 'predictions_assists.csv'  # Update this path as needed\n",
    "final_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to '{output_file_path}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
